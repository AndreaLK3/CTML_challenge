{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa6426f4",
   "metadata": {},
   "source": [
    "## CTML Take-Home Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcc7001",
   "metadata": {},
   "source": [
    "### Challenge 1: Breast Cancer Dataset EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144ebc9e",
   "metadata": {},
   "source": [
    "#### The dataset \n",
    "The dataset is stored in the `wdbc.data` CSV file, which has 569 comma-separated lines and no headers.\n",
    "<br/>\n",
    "\n",
    "The meaning of the columns is specified in the `wdbc.names` text file:\n",
    "<br/>\n",
    "- field 1: **ID number**\n",
    "- field 2: **Diagnosis** (M = malignant, B = benign) \n",
    "- fields 3 to 32: The mean, standard error, and \"worst\" or largest (mean of the three largest values) of the **features** computed for each image.\n",
    "(For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.)\n",
    "\n",
    "After the necessary imports, we define the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7f21cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from math import sqrt, exp, log, pi\n",
    "from sklearn import svm, metrics, ensemble\n",
    "import numpy as np\n",
    "import itertools \n",
    "from IPython.display import Markdown as md, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98664ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_fpath = \"wdbc.data\"\n",
    "\n",
    "element_names = [\"mean\", \"standard_err\", \"largest\"]\n",
    "\n",
    "feature_names = [\"radius\", \"texture\", \"perimeter\", \"area\", \"smoothness\", \"compactness\", \"concavity\", \n",
    "                 \"concave_points\", \"symmetry\", \"fractal_dimension\"]\n",
    "column_names = [\"ID\",  \"diagnosis\"] + [feat + \" \" + el for el in element_names for feat in feature_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e96396",
   "metadata": {},
   "source": [
    "**a. What are the mean, median and standard deviation of the “perimeter” feature?**\n",
    "\n",
    "To compute these statistics on the perimeter feature, we use the entries of the \"perimeter mean\" column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66b205f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Perimeter mean = 91.97"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataset_fpath, names=column_names)\n",
    "\n",
    "perimeter_mean_entries = df[\"perimeter mean\"].tolist()\n",
    "perimeter_mean_overall = sum(perimeter_mean_entries) / len(perimeter_mean_entries)\n",
    "\n",
    "md(\"Perimeter mean = {}\".format(str(round(perimeter_mean_overall,2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05e16d96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Perimeter median = 86.24"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# median\n",
    "perimeter_mean_entries_sorted = sorted(perimeter_mean_entries)\n",
    "midpoint = len(perimeter_mean_entries) // 2\n",
    "perimeter_median = perimeter_mean_entries_sorted[midpoint]\n",
    "\n",
    "md(\"Perimeter median = {}\".format(str(round(perimeter_median, 2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92a468b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Perimeter standard deviation = 24.28"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# standard deviation\n",
    "\n",
    "squared_diffs = [(x_i - perimeter_mean_overall)**2 for x_i in perimeter_mean_entries]\n",
    "num_samples = len(squared_diffs)\n",
    "perimeter_std_dev = sqrt(sum(squared_diffs) / num_samples)\n",
    "md(\"Perimeter standard deviation = {}\".format(str(round(perimeter_std_dev, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4d82d",
   "metadata": {},
   "source": [
    "**b. Is the first feature in this data set (the “radius”) normally distributed? Quantify your answer.**\n",
    "\n",
    "If not, what might be a more appropriate statistical distribution for modelling purposes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b02766d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAToklEQVR4nO3df5DWdb338edbwBAtfg+ZWIsezGBhURfwVkPTAhNCDRQ0iVAjNO+yU9xyn1FYsho8Q0cPVDCelMGGOhRmNKKeNHGUfjBnQbr9AWcU3TxrpIiCBxxS5HP/sRfbivvjWnaX3Q/7fMwwe31/XZ83n/ny2g+f63t9v5FSQpKUn6PauwBJ0qExwCUpUwa4JGXKAJekTBngkpSproezsX79+qWSkpLD2aQkZW/Dhg2vpZT6H7z+sAZ4SUkJlZWVh7NJScpeRPy5vvVOoUhSpgxwScqUAS5JmTqsc+BSR/TOO+9QXV3N3r1727sUdXLdu3dn4MCBdOvWraj9DXB1etXV1Xzwgx+kpKSEiGjvctRJpZTYsWMH1dXVDBo0qKhjnEJRp7d371769u1reKtdRQR9+/Zt1v8EDXAJDG91CM09Dw1wScqUc+DSQUrmrGnV96taML7JfRYtWsSSJUs4/fTTWbFiRau239Fs2bKFqVOnEhGsWrWKk08+uUXvV1VVxYQJE3j66aeprKzknnvuYdGiRa1UbXG+9KUvMWHCBCZPnnxY2zXAO7CWBEkxoaGO40c/+hGPPPIIAwcOfM/6ffv20bXrkfXP9Fe/+hWTJ0/m5ptvbnS/d999ly5dujTrvcvLyykvL29JeVlxCkVqZ7NmzeKFF17gs5/9LLfffjsVFRVMmzaNs88+m2nTprF9+3YmTZrEyJEjGTlyJL/73e8A2LFjB2PHjmXo0KFce+21fOxjH+O1116jqqqK0tLS2vdfuHAhFRUVAGzdupULL7yQM844g09+8pNs2bIFqBlBfu1rX+Oss87ipJNOYtWqVbXH33bbbQwbNoyysjLmzJnD1q1bOf3002u3P/fcc+9ZPmDTpk2ceeaZDB8+nEsvvZQ33niDBx54gDvuuIMlS5bwqU996n3HHHfccXzzm9+krKyMP/zhD3z7299m5MiRlJaWMnPmTA48QWzDhg2UlZVRVlbGD3/4w9rjH3vsMSZMmABARUUFCxcurN1WWlpKVVUVe/bsYfz48ZSVlVFaWsrKlSvfU8OWLVsYNWpU7XJVVRXDhg0DaLCeukpKSnjttdcAqKys5LzzzgNgz549XH311YwaNYrTTjuN1atXv+/Y5jqyfrWrlqP3fCxdupSHHnqItWvX0q9fPyoqKnj22WdZt24dxxxzDFdeeSXf+MY3OOecc3jppZcYN24cmzdvZv78+ZxzzjnMnTuXNWvWcNdddzXZ1syZM1m6dCmDBw9m/fr1XH/99Tz66KMAbNu2jXXr1rFlyxYmTpzI5MmTefDBB1m9ejXr16+nR48evP766/Tp04eePXuyadMmRowYwbJly5gxY8b72vriF7/I4sWLOffcc5k7dy7z58/njjvuYNasWRx33HF861vfet8xe/bsYfTo0Xz/+98HYMiQIcydOxeAadOmcf/99/O5z32OGTNm8IMf/IAxY8Ywe/bsZvX3Qw89xEc+8hHWrKn5N7Jr1673bD/11FN5++23efHFFxk0aBArV65kypQpANxwww311lOM7373u5x//vncfffd7Ny5k1GjRvHpT3+aY489tln11+UIXOqAJk6cyDHHHAPAI488wg033MCIESOYOHEib775Jrt37+bxxx/nqquuAmD8+PH07t270ffcvXs3v//977nssssYMWIEX/nKV9i2bVvt9ksuuYSjjjqKIUOG8Morr9S2PWPGDHr06AFAnz59ALj22mtZtmwZ7777LitXruTKK698T1u7du1i586dnHvuuQBMnz6dxx9/vMm/d5cuXZg0aVLt8tq1axk9ejTDhg3j0Ucf5ZlnnmHnzp3s3LmTMWPGADVB2hzDhg3j4Ycf5qabbuKJJ56gZ8+e79vn8ssvrx2Z1w3w+uop1m9+8xsWLFjAiBEjOO+889i7dy8vvfRSs2o/mCNwqQOqOyrbv38/f/zjH+nevXtRx3bt2pX9+/fXLh+4rnj//v306tWLTZs21XvcBz7wgdrXTT3sfNKkScyfP5/zzz+fM844g759+xZVW1O6d+9eO++9d+9err/+eiorKznxxBOpqKho1jXSDfXDKaecwsaNG3nggQe4+eabueCCC2pH1QdMmTKFyy67jM9//vNEBIMHDy66nrrt1t2eUuLee+/l4x//ePEd0gRH4FIHN3bsWBYvXly7fCCAx4wZw09/+lMAHnzwQd544w0ABgwYwKuvvsqOHTv429/+xv333w/Ahz70IQYNGsQvfvELoCZQ/vSnPzXa9mc+8xmWLVvGW2+9BcDrr78O1ATtuHHjuO666+qdPunZsye9e/fmiSeeAOAnP/lJ7Wi8WAfCr1+/fuzevbt2Xr5Xr1706tWLdevWATR41U5JSQkbN24EYOPGjbz44osA/OUvf6FHjx5cddVVzJ49u3afuk4++WS6dOnCrbfeWjv6bqie+trdsGEDAPfee2/t+nHjxrF48eLaX45PPvlkM3qjfo7ApYN0tM8AFi1axFe/+lWGDx/Ovn37GDNmDEuXLmXevHlcccUVDB06lLPOOouPfvSjAHTr1o25c+cyatQoTjjhBE499dTa91qxYgXXXXcd3/nOd3jnnXeYOnUqZWVlDbZ94YUXsmnTJsrLyzn66KO56KKL+N73vgfAF77wBe677z7Gjh1b77HLly9n1qxZvPXWW5x00kksW7asWX/vXr168eUvf5nS0lI+/OEPM3LkyNpty5Yt4+qrryYiGmx/0qRJ3HPPPQwdOpTRo0dzyimnAPDUU08xe/ZsjjrqKLp168aSJUvqPX7KlCnMnj27Nvgbq6euefPmcc0113DLLbfUfoAJcMstt3DjjTcyfPhw9u/fz6BBg2p/uR6qaOq/Sq2pvLw8+UCH4rX29cjF6mgB1tY2b97MJz7xifYuo8UOPDClX79+h6W9hQsXsmvXLm699dbD0l5nUd/5GBEbUkrvuz7SEbikZrv00kvZunVr7RUsah8GuHSEqKqqOmxt3XfffYetLTXMDzElmr7qQjocmnseGuDq9Lp3786OHTsMcbWrA/cDL/ZyUXAKRWLgwIFUV1ezffv29i5FndyBJ/IUywBXp9etW7ein4AidSROoUhSpgxwScqUAS5JmTLAJSlTBrgkZcoAl6RMGeCSlCkDXJIyZYBLUqYMcEnKlAEuSZkywCUpU0UFeER8IyKeiYinI+JnEdE9IgZFxPqIeD4iVkbE0W1drCTp75oM8Ig4AfgaUJ5SKgW6AFOB24DbU0r/ALwBXNOWhUqS3qvYKZSuwDER0RXoAWwDzgdWFbYvBy5p9eokSQ1qMsBTSi8DC4GXqAnuXcAGYGdKaV9ht2rghPqOj4iZEVEZEZXeMF+SWk8xUyi9gYuBQcBHgGOBC4ttIKV0Z0qpPKVU3r9//0MuVJL0XsVMoXwaeDGltD2l9A7wS+BsoFdhSgVgIPByG9UoSapHMQH+EnBmRPSIiAAuAJ4F1gKTC/tMB1a3TYmSpPoUMwe+npoPKzcCTxWOuRO4CfjHiHge6Avc1YZ1SpIOUtRDjVNK84B5B61+ARjV6hVJkoriNzElKVMGuCRlygCXpEwZ4JKUKQNckjJlgEtSpgxwScqUAS5JmTLAJSlTBrgkZcoAl6RMGeCSlCkDXJIyZYBLUqaKup2sOpeSOWtadHzVgvGtVImkxjgCl6RMGeCSlCkDXJIyZYBLUqYMcEnKlAEuSZkywCUpUwa4JGXKAJekTBngkpQpA1ySMmWAS1KmDHBJypQBLkmZMsAlKVMGuCRlygCXpEwZ4JKUKQNckjJlgEtSpooK8IjoFRGrImJLRGyOiP8VEX0i4uGIeK7ws3dbFytJ+rtiR+D/CjyUUjoVKAM2A3OA36aUBgO/LSxLkg6TJgM8InoCY4C7AFJKb6eUdgIXA8sLuy0HLmmbEiVJ9SlmBD4I2A4si4gnI+LHEXEsMCCltK2wz1+BAfUdHBEzI6IyIiq3b9/eOlVLkooK8K7A6cCSlNJpwB4Omi5JKSUg1XdwSunOlFJ5Sqm8f//+La1XklRQTIBXA9UppfWF5VXUBPorEXE8QOHnq21ToiSpPk0GeErpr8B/R8THC6suAJ4Ffg1ML6ybDqxukwolSfXqWuR+/xtYERFHAy8AM6gJ/59HxDXAn4HL26ZESVJ9igrwlNImoLyeTRe0ajU6IpTMWXPIx1YtGN+KlUhHNr+JKUmZMsAlKVMGuCRlygCXpEwZ4JKUKQNckjJlgEtSpgxwScqUAS5JmTLAJSlTBrgkZcoAl6RMGeCSlCkDXJIyZYBLUqYMcEnKlAEuSZkywCUpUwa4JGXKAJekTBngkpSpop5Kr0PXkie0S1JjHIFLUqYMcEnKlAEuSZkywCUpUwa4JGXKAJekTBngkpQpA1ySMmWAS1KmDHBJypQBLkmZMsAlKVMGuCRlygCXpEwVHeAR0SUinoyI+wvLgyJifUQ8HxErI+LotitTknSw5ozAvw5srrN8G3B7SukfgDeAa1qzMElS44oK8IgYCIwHflxYDuB8YFVhl+XAJW1QnySpAcWOwO8A/g+wv7DcF9iZUtpXWK4GTqjvwIiYGRGVEVG5ffv2ltQqSaqjyQCPiAnAqymlDYfSQErpzpRSeUqpvH///ofyFpKkehTzTMyzgYkRcRHQHfgQ8K9Ar4joWhiFDwRebrsyJUkHa3IEnlL6vymlgSmlEmAq8GhK6QvAWmByYbfpwOo2q1KS9D4tuQ78JuAfI+J5aubE72qdkiRJxShmCqVWSukx4LHC6xeAUa1fkiSpGH4TU5IyZYBLUqYMcEnKlAEuSZkywCUpUwa4JGXKAJekTBngkpQpA1ySMmWAS1KmDHBJypQBLkmZatbNrKS2VjJnzSEfW7VgfCtWInV8jsAlKVOOwJvQkhGhJLUlR+CSlCkDXJIyZYBLUqYMcEnKlAEuSZnyKhSphVp6pZLXr+tQOQKXpEwZ4JKUKadQpHbm7QN0qByBS1KmDHBJypQBLkmZMsAlKVMGuCRlygCXpEwZ4JKUKQNckjLlF3l0xPALMepsHIFLUqYcgUv47FPlqckReEScGBFrI+LZiHgmIr5eWN8nIh6OiOcKP3u3fbmSpAOKmULZB3wzpTQEOBP4akQMAeYAv00pDQZ+W1iWJB0mTQZ4SmlbSmlj4fX/AJuBE4CLgeWF3ZYDl7RRjZKkejTrQ8yIKAFOA9YDA1JK2wqb/goMaOCYmRFRGRGV27dvb0mtkqQ6ig7wiDgOuBe4MaX0Zt1tKaUEpPqOSyndmVIqTymV9+/fv0XFSpL+rqgAj4hu1IT3ipTSLwurX4mI4wvbjwdebZsSJUn1KeYqlADuAjanlP6lzqZfA9MLr6cDq1u/PElSQ4q5DvxsYBrwVERsKqz7J2AB8POIuAb4M3B5m1QoSapXkwGeUloHRAObL2jdciRJxfKr9JKUKQNckjJlgEtSpgxwScqUAS5JmeoUt5P1VqGSjkSOwCUpUwa4JGXKAJekTBngkpQpA1ySMmWAS1KmDHBJypQBLkmZ6hRf5JGOVC35klrVgvGtWInagyNwScqUAS5JmTLAJSlTBrgkZcoAl6RMGeCSlCkDXJIyZYBLUqYMcEnKlAEuSZkywCUpUwa4JGXKAJekTHk3QknN1pK7IIJ3QmwtjsAlKVPZjMBb+htfko40jsAlKVPZjMAlqT11xKcfOQKXpEw5Apc6qfb8XKm92j7Srn5xBC5JmWpRgEfEhRHxXxHxfETMaa2iJElNO+QAj4guwA+BzwJDgCsiYkhrFSZJalxLRuCjgOdTSi+klN4G/h24uHXKkiQ1pSUfYp4A/Hed5Wpg9ME7RcRMYGZhcXdE/FcL2sxJP+C19i6iA7N/Gmf/NO6Q+idua4NKDk+7H6tvZZtfhZJSuhO4s63b6WgiojKlVN7edXRU9k/j7J/G2T81WjKF8jJwYp3lgYV1kqTDoCUB/p/A4IgYFBFHA1OBX7dOWZKkphzyFEpKaV9E3AD8B9AFuDul9EyrVZa/Tjdt1Ez2T+Psn8bZP0CklNq7BknSIfCbmJKUKQNckjJlgLdQRNwdEa9GxNN11vWJiIcj4rnCz97tWWN7aqB/KiLi5YjYVPhzUXvW2J4i4sSIWBsRz0bEMxHx9cJ6zyEa7R/PIZwDb7GIGAPsBu5JKZUW1v0z8HpKaUHhHjG9U0o3tWed7aWB/qkAdqeUFrZnbR1BRBwPHJ9S2hgRHwQ2AJcAX8JzqLH+uRzPIUfgLZVSehx4/aDVFwPLC6+XU3PCdUoN9I8KUkrbUkobC6//B9hMzbecPYdotH+EAd5WBqSUthVe/xUY0J7FdFA3RMT/K0yxdMrpgYNFRAlwGrAez6H3Oah/wHPIAG9rqWaOynmq91oCnAyMALYB32/XajqAiDgOuBe4MaX0Zt1tnkP19o/nEAZ4W3mlMHd3YA7v1Xaup0NJKb2SUno3pbQf+Ddq7mzZaUVEN2rCaUVK6ZeF1Z5DBfX1j+dQDQO8bfwamF54PR1Y3Y61dDgHgqngUuDphvY90kVEAHcBm1NK/1Jnk+cQDfeP51ANr0JpoYj4GXAeNbe3fAWYB/wK+DnwUeDPwOUppU75QV4D/XMeNf/1TUAV8JU6872dSkScAzwBPAXsL6z+J2rmeTv9OdRI/1yB55ABLkm5cgpFkjJlgEtSpgxwScqUAS5JmTLAJSlTBrgkZcoAl6RM/X/o+61qUxSJawAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "After representing the radius feature with a histogram, we state that it does not follow a normal distribution, because it is not symmetric.\n",
       "\n",
       "This is confirmed by the fact that the Fisher-Pearson skewness coefficient is different from 0. \n",
       "<br>Skewness coeff.=0.94"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "radius_mean_entries = df[\"radius mean\"].tolist()\n",
    "radius_sample_mean = round(sum(radius_mean_entries) / len(radius_mean_entries),2)\n",
    "radius_squared_diffs = [(x_i - radius_sample_mean)**2 for x_i in radius_mean_entries]\n",
    "radius_std_dev = sqrt(sum(radius_squared_diffs) / len(radius_squared_diffs))\n",
    "\n",
    "# plot bins\n",
    "n,bins,patches = plt.hist(radius_mean_entries, bins=20, label=\"frequency of radius value\")\n",
    "plt.legend()\n",
    "plt.savefig(\"Radius_frequency.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "skew_coefficient = (sum([(x_i - radius_sample_mean)**3 for x_i in radius_mean_entries]) \\\n",
    "                    / len(radius_mean_entries))                                         \\\n",
    "                    /(radius_std_dev**3)\n",
    "md(\"\"\"After representing the radius feature with a histogram, we state that it does not follow a normal distribution, because it is not symmetric.\n",
    "\n",
    "This is confirmed by the fact that the Fisher-Pearson skewness coefficient is different from 0. \n",
    "<br>Skewness coeff.={}\"\"\".format(round(skew_coefficient,2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "241e22d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "We hypothesize that the log-normal distribution would be a better fit for the radius feature, as seen in the following image:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md(\"We hypothesize that the log-normal distribution would be a better fit for the radius feature, as seen in the following image:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2e6d53",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"log-normal.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
    "<td> <img src=\"Radius_frequency.png\" alt=\"Drawing\" style=\"width: 350px;\"/> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec1fda9",
   "metadata": {},
   "source": [
    "**c. Train a classifier to predict the diagnosis of malignant or benign.**\n",
    "\n",
    "Compare the results of two classifiers (e.g. SVM, logistic regression and/or decision tree) and make some suggestions on how the classifier’s performance could be further improved.\n",
    "\n",
    "We start by standardizing the data columns to have mean=0 and standard deviation=1, since several classification models are sensitive to numerical scale and would place undue importance on numerically larger features.\n",
    "\n",
    "Then, we split the dataset into 90% training set and 10% test set, to verify the models' perfomance on data they were not trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e5a5482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminary step 1: normalize/standardize the data columns\n",
    "# Choosing: standardization to \\mu=0 and \\sigma=1\n",
    "df_standardized = df.copy()\n",
    "for feature_col in column_names[2:]:  # skip \"ID\" and \"Diagnosis\"\n",
    "    col_ls = df[feature_col].tolist()\n",
    "    col_avg = sum(col_ls) / len(col_ls)\n",
    "    col_squared_diffs = [(x_i - col_avg)**2 for x_i in col_ls]\n",
    "    col_std_dev = sqrt(sum(col_squared_diffs) / len(col_squared_diffs))\n",
    "    df_standardized[feature_col] = df_standardized[feature_col].map(lambda val: (val - col_avg)/col_std_dev)\n",
    "    \n",
    "\n",
    "df_standardized['diagnosis'] = df_standardized['diagnosis'].map(lambda label: 1 if label==\"M\" else 0)\n",
    "\n",
    "# Preliminary step 2: split into training and test sets\n",
    "n = df_standardized.index.stop\n",
    "training_df = df_standardized.iloc[:int(9/10*n),].copy()\n",
    "training_labels_df = training_df[\"diagnosis\"]\n",
    "training_df.drop(columns=[\"ID\", \"diagnosis\"], inplace=True)\n",
    "\n",
    "test_df = df_standardized.iloc[int(9/10*n):n,].copy()\n",
    "test_labels_df = test_df[\"diagnosis\"]\n",
    "test_df.drop(columns=[\"ID\", \"diagnosis\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "150e6a88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "test labels: # benign=43 ; # malignant=14\n",
       "\n",
       "Classifier : Support Vector Machine (exponential kernel)\n",
       "\n",
       "Accuracy=0.947\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transform columns into numpy arrays for the SVC\n",
    "training_x = training_df.to_numpy()\n",
    "training_y = training_labels_df.to_numpy()\n",
    "test_x = test_df.to_numpy()\n",
    "test_y = test_labels_df.to_numpy()\n",
    "\n",
    "svc = svm.SVC(cache_size=500)\n",
    "svc.fit(training_x, training_y)\n",
    "predicted_labels = svc.predict(test_x)\n",
    "\n",
    "md(\"\"\"test labels: # benign={} ; # malignant={}\n",
    "\n",
    "Classifier : Support Vector Machine (exponential kernel)\n",
    "\n",
    "Accuracy={}\n",
    "\n",
    "\"\"\".format(np.count_nonzero(test_y==0), np.count_nonzero(test_y==1), \n",
    "          round(metrics.accuracy_score(test_y, predicted_labels),3)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76a1bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix :\n",
      " \t true_benign   |  false malignant  \n",
      " \t false benign  | true malignant\n",
      "[[41  2]\n",
      " [ 1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix :\\n \\t true_benign   |  false malignant  \\n \\t false benign  | true malignant\" )\n",
    "print(str(metrics.confusion_matrix(test_y, predicted_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c37fe600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Classifier : Random forest\n",
       "\n",
       "Accuracy=0.982\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randforest = ensemble.RandomForestClassifier(max_depth=2, random_state=0)\n",
    "randforest.fit(training_x, training_y)\n",
    "y_pred = randforest.predict(test_x)\n",
    "\n",
    "md(\"\"\"Classifier : Random forest\n",
    "\n",
    "Accuracy={}\n",
    "\n",
    "\"\"\".format(round(metrics.accuracy_score(test_y, y_pred), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8cf509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      "[[43  0]\n",
      " [ 1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix:\\n\" + str(metrics.confusion_matrix(test_y, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb350094",
   "metadata": {},
   "source": [
    "There are several ways the classifiers' performance could be improved:\n",
    "1. Train them on a larger dataset, and run inference on a larger test dataset as well. While the classification accuracy and confusion matrix in this small experiment are satisfactory, it would be opportune to have better guarantees of the generalization capability\n",
    "2. Use grid-search to find the best model hyperparameters: tree number and maximum depth for Random Forests, kernel function parameters for Support Vector Machines\n",
    "3. Early stopping: make a validation dataset and use it to stop training when the performance on non-training data stops improving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa2d9e32",
   "metadata": {},
   "source": [
    "### Challenge 2: Spearman’s Footrule Distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71da7223",
   "metadata": {},
   "source": [
    "Spearman’s Footrule Distance computes the distance between two rankings.\n",
    "\n",
    "The objective is to implement the function `sumSpearmanDistances(scores, proposedRanking)`, which computes the sum of Spearman’s Footrule Distances for a given proposedRanking.\n",
    " \n",
    "Functions implemented: \n",
    "- `test_case_generator()`: get score dictionaries, proposed rankings, and intended results for 3 test cases\n",
    "- `computeSpearmanDistance(metric_score_dict, proposedRanking)`: compute the Spearman distance for the set of scores from one metric and the proposed ranking\n",
    "- `sumSpearmanDistances(scores, proposedRanking)`: the target function\n",
    "- `test_sumSpearmanDistances()`: apply the target function to the provided test cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17fda183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_case_generator():\n",
    "    \"\"\" For our examples, get several score dictionaries, proposed rankings, and intended results \"\"\"\n",
    "    scores_1 = {'A': [100, 0.1], 'B': [90, 0.3], 'C': [20, 0.2]}\n",
    "    scores_2 = {'A': [50, 0.5], 'B': [70, 0.3], 'C': [30, 0.1], 'D': [90, 0.5], 'E': [60, 0.4]}\n",
    "    scores_ls = [scores_1, scores_2]\n",
    "    \n",
    "    proposed_ranking_1a = ['A','B','C']\n",
    "    # distance metric 1: 0 ; distance metric 2: 2+1+1=4 \n",
    "    expected_sum_1a = 4\n",
    "    \n",
    "    proposed_ranking_1b = ['C','B','A']\n",
    "    # distance metric 1: 2+0++2=4 ; distance metric 2: 1+1+0=2\n",
    "    expected_sum_1b = 6\n",
    "    \n",
    "    proposed_ranking_2a = ['A','B','C','D','E']\n",
    "    # distance metric 1: 3+0+2+3+2=10 ; distance metric 2: 0+2+2+3+3=8\n",
    "    expected_sum_2a = 18\n",
    "    \n",
    "    test_cases = [(scores_1, proposed_ranking_1a, expected_sum_1a), \n",
    "                (scores_1, proposed_ranking_1b, expected_sum_1b), \n",
    "                (scores_2, proposed_ranking_2a, expected_sum_2a)]\n",
    "    \n",
    "    for i in range(len(test_cases)):\n",
    "        yield test_cases[i]\n",
    "        \n",
    "\n",
    "        \n",
    "def computeSpearmanDistance(metric_score_dict, proposedRanking):\n",
    "    \"\"\"metric_score: a dict with key=item_name and value=score according to one metric\"\"\"\n",
    "    \n",
    "    scored_items = list(metric_score_dict.keys())\n",
    "    scored_items.sort(key=lambda x: metric_score_dict[x], reverse=True)\n",
    "    # print(\"Proposed ranking:           \" + str(proposedRanking))\n",
    "    # print(\"Sorted according to metric: \" + str(scored_items))  Debugging\n",
    "    \n",
    "    spearman_distance = 0\n",
    "    for i, elem in enumerate(proposedRanking):\n",
    "        place_in_metric = scored_items.index(elem)\n",
    "        spearman_distance = spearman_distance + (abs(i-place_in_metric))\n",
    "    print(\"Spearman distance = \" + str(spearman_distance))\n",
    "        \n",
    "    return spearman_distance\n",
    "        \n",
    "        \n",
    "    \n",
    "def sumSpearmanDistances(scores, proposedRanking):\n",
    "    \n",
    "    items = list(scores.keys())\n",
    "       \n",
    "    num_metrics = len(scores[items[0]])\n",
    "    sum_spearman_distances = 0\n",
    "        \n",
    "    for metric_i in range(0,num_metrics):  # for each metric in the scores' dictionary:\n",
    "        metric_score = dict()\n",
    "        for item in proposedRanking:\n",
    "            metric_score[item] = scores[item][metric_i]\n",
    "        metric_dist = computeSpearmanDistance(metric_score, proposedRanking)\n",
    "        sum_spearman_distances = sum_spearman_distances + metric_dist\n",
    "    \n",
    "    return sum_spearman_distances\n",
    "\n",
    "    \n",
    "def test_sumSpearmanDistances():\n",
    "    \n",
    "    for (scores, proposedRanking, expected_sum) in test_case_generator():\n",
    "        sum_spearman_distances = sumSpearmanDistances(scores, proposedRanking)\n",
    "        \n",
    "        print(\"Computed sum of Spearman distances = \" + str(sum_spearman_distances) + \" ; \" + \\\n",
    "              \"Expected = \" + str(expected_sum))\n",
    "        \n",
    "        if sum_spearman_distances != expected_sum:\n",
    "            raise Exception\n",
    "        else:\n",
    "            print(\"Test OK\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "400b6433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman distance = 0\n",
      "Spearman distance = 4\n",
      "Computed sum of Spearman distances = 4 ; Expected = 4\n",
      "Test OK\n",
      "\n",
      "Spearman distance = 4\n",
      "Spearman distance = 2\n",
      "Computed sum of Spearman distances = 6 ; Expected = 6\n",
      "Test OK\n",
      "\n",
      "Spearman distance = 10\n",
      "Spearman distance = 8\n",
      "Computed sum of Spearman distances = 18 ; Expected = 18\n",
      "Test OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sumSpearmanDistances()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1ce7b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
